{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Pruefer\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import redis\n",
    "\n",
    "redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9304c4cb77bf4284",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "system_prompt_initial = \"\"\"\n",
    "Du bist Englischlehrer.\n",
    "Du prüfst ob die Zeitform richtig benutzt wurde und der Satz somit grammatikalisch korrekt ist.\n",
    "\"\"\"\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(system_prompt_initial),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Der Schüler hatte als Aufgabe den deutschen Satz erhalten: {examiner_sentence_german}\n",
    "            \n",
    "                Der Schüler hätte den Satz in der Zeitform {examiner_requested_tense} übersetzen sollen.\n",
    "                \n",
    "                Hat der Schüler die Aufgabe richtig beantwortet?\n",
    "                Antwort ausschließlich mit TRUE oder FALSE\n",
    "        \"\"\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    #model=\"gpt-4-0125-preview\",\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    streaming=True,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "grammar_checker = prompt | llm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5aff865fc7d470fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "system_prompt_initial = \"\"\"Du bist Knowledge Master und koordinierst die Tools.\n",
    "\"\"\"\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(system_prompt_initial),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"Vorhandene Records:\n",
    "            '''\n",
    "            {knowledge}\n",
    "            '''\n",
    "            \n",
    "            Prüfe anhand der vorhandenen Einträge ob es einen inhaltlich gleichen Eintrag gibt wie diesen hier:\n",
    "            '''\n",
    "            {mistakes_made}\n",
    "            '''\n",
    "\n",
    "            Wenn es einen Eintrag bereits der das gleiche meint, bist du fertig.\n",
    "            Wenn es noch keinen Eintrag gibt, erstelle einen solchen neuen Eintrag.\n",
    "            Wenn sich das Sachverhalte inhaltlich geändert hat, modifiziere diesen Eintrag          \n",
    "        \"\"\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4-0125-preview\",\n",
    "    #model=\"gpt-3.5-turbo-0125\",\n",
    "    streaming=True,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "tools = [convert_to_openai_function(t) for t in agent_tools]\n",
    "\n",
    "examiner_runnable = prompt | llm.bind_tools(tools)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd50a25b0cf4a4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import operator\n",
    "from typing import TypedDict, Sequence, Annotated\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Sequence[BaseMessage]\n",
    "    #messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    bewerter_shortener_scratchpad: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "    #Context from Examiner Agent\n",
    "    student_sentence_english: str\n",
    "\n",
    "    examiner_sentence_german: str\n",
    "    examiner_sentence_english: str\n",
    "    examiner_requested_tense: str\n",
    "    examiner_topics: str\n",
    "\n",
    "    #Decision Variables:\n",
    "    exercise_correct: str\n",
    "    grammar_correct: str\n",
    "\n",
    "    problem: str\n",
    "\n",
    "    mistakes_made: str\n",
    "    \n",
    "    knowledge: str"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed7c4c79a5b76b3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sprachtrainer.agents import bewerter_agent\n",
    "from sprachtrainer.agents import empfehler_agent\n",
    "from sprachtrainer.agents import shortener_agent\n",
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "\n",
    "\n",
    "def call_examiner(state):\n",
    "    mistakes_made = state[\"mistakes_made\"]\n",
    "    response = examiner_runnable.invoke(\n",
    "        {\"mistakes_made\": mistakes_made,\n",
    "         \"knowledge\": get_knowledge_comma_separated()}\n",
    "    )\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def call_grammar_checker(state):\n",
    "    messages = state[\"messages\"]\n",
    "    examiner_sentence_german = state[\"examiner_sentence_german\"]\n",
    "    examiner_requested_tense = state[\"examiner_requested_tense\"]\n",
    "    response = grammar_checker.invoke(\n",
    "        {\"messages\": messages,\n",
    "         \"examiner_sentence_german\": examiner_sentence_german,\n",
    "         \"examiner_requested_tense\": examiner_requested_tense\n",
    "         }\n",
    "    )\n",
    "    return {\"grammar_correct\": \"TRUE\" in response.content and \"yes\" or \"no\"}\n",
    "\n",
    "\n",
    "def call_bewerter(state):\n",
    "    student_sentence_english = state[\"student_sentence_english\"]\n",
    "    examiner_sentence_english = state[\"examiner_sentence_english\"]\n",
    "    bewerter_shortener_scratchpad = state[\"bewerter_shortener_scratchpad\"]\n",
    "\n",
    "    response = bewerter_agent.getBewerterAgent().invoke(\n",
    "        {\n",
    "            \"student_sentence_english\": student_sentence_english,\n",
    "            \"examiner_sentence_english\": examiner_sentence_english,\n",
    "            \"bewerter_shortener_scratchpad\": bewerter_shortener_scratchpad  \n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Rückgabe der Analyseergebnisse als Dictionary\n",
    "    return {\"mistakes_made\": response.content}\n",
    "\n",
    "\n",
    "def call_shortener(state):\n",
    "    mistakes_made = state[\"mistakes_made\"]\n",
    "    response = shortener_agent.getShortenerAgent().invoke(\n",
    "        {\n",
    "            \"mistakes_made\": mistakes_made,\n",
    "        }\n",
    "    )\n",
    "    return {\"mistakes_made\": response}\n",
    "\n",
    "\n",
    "def call_empfehler(state):\n",
    "    student_sentence_english = state[\"student_sentence_english\"]\n",
    "    examiner_sentence_english = state[\"examiner_sentence_english\"]\n",
    "    mistakes_made = state[\"mistakes_made\"]\n",
    "    response = empfehler_agent.getEmpfehlerAgent().invoke(\n",
    "        {\n",
    "            \"student_sentence_english\": student_sentence_english,\n",
    "            \"mistakes_made\": mistakes_made,\n",
    "            \"examiner_sentence_english\": examiner_sentence_english\n",
    "        }\n",
    "    )\n",
    "    return {\"mistakes_made\": response.content}\n",
    "\n",
    "\n",
    "def call_tool(state):\n",
    "    messages = state[\"messages\"]\n",
    "    # We know the last message involves at least one tool call\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # We loop through all tool calls and append the message to our message log\n",
    "    for tool_call in last_message.additional_kwargs[\"tool_calls\"]:\n",
    "        action = ToolInvocation(\n",
    "            tool=tool_call[\"function\"][\"name\"],\n",
    "            tool_input=json.loads(tool_call[\"function\"][\"arguments\"]),\n",
    "            id=tool_call[\"id\"],\n",
    "        )\n",
    "\n",
    "        # We call the tool_executor and get back a response\n",
    "        response = tool_executor.invoke(action)\n",
    "        # We use the response to create a FunctionMessage\n",
    "        function_message = ToolMessage(\n",
    "            content=str(response), name=action.tool, tool_call_id=tool_call[\"id\"]\n",
    "        )\n",
    "\n",
    "        # Add the function message to the list\n",
    "        messages.append(function_message)\n",
    "    return {\"messages\": messages}\n",
    "\n",
    "\n",
    "def should_continue(state):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    # If there are no tool calls, then we finish\n",
    "    if \"tool_calls\" not in last_message.additional_kwargs:\n",
    "        return \"end\"\n",
    "    # Otherwise, we continue\n",
    "    else:\n",
    "        return \"continue\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a68322e58b95751c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Initialize a new graph \n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"grammar_checker\", call_grammar_checker)\n",
    "graph.add_node(\"bewerter_agent\", call_bewerter)\n",
    "graph.add_node(\"shortener_agent\", call_shortener)\n",
    "graph.add_node(\"empfehler_agent\", call_empfehler)\n",
    "graph.add_node(\"examiner\", call_examiner)\n",
    "graph.add_node(\"action\", call_tool)\n",
    "\n",
    "graph.set_entry_point(\"grammar_checker\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"grammar_checker\",\n",
    "    lambda x: x[\"grammar_correct\"],\n",
    "    {\n",
    "        \"yes\": \"examiner\",\n",
    "        \"no\": \"bewerter_agent\",\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"examiner\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"action\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_edge(\"action\", END)\n",
    "graph.add_edge(\"bewerter_agent\", \"shortener_agent\")\n",
    "graph.add_edge(\"shortener_agent\", \"empfehler_agent\")\n",
    "graph.add_edge(\"empfehler_agent\", \"examiner\")\n",
    "\n",
    "# We compile the entire workflow as a runnable\n",
    "app_agent = graph.compile()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1feacfa5bb9d976b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "message = \"I have been reading a car for two hours.\"\n",
    "\n",
    "inputs = {\n",
    "    \"examiner_sentence_german\": \"Ich lese seit zwei Stunden ein Buch.\",\n",
    "    \"student_sentence_english\": message,\n",
    "    #\"student_sentence_english\": \"I have been reading a book for two hours.\",\n",
    "    \"examiner_requested_tense\": \"Present Perfect Continuous\",\n",
    "    \"examiner_sentence_english\": \"I have been reading a book for two hours.\",\n",
    "    \"examiner_topics\": get_knowledge_comma_separated(),\n",
    "    \"messages\": [HumanMessage(content=message)]\n",
    "}\n",
    "\n",
    "for output in app_agent.with_config({\"run_name\": \"Examiner\"}).stream(inputs):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d7fe3e9b39184b3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
